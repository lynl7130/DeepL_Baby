
# Rich feature hierarchies for accurate object detection and semantic segmentation

[CVPR 2014 Paper](https://arxiv.org/pdf/1311.2524.pdf)

## Summary
### MAP
[Tutorial](https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173)  
* MAP is the mean across classes of APs(binary), sometimes is also called AP.  

### R-CNN:Regions with CNN features
#### Two key insights:  
1. apply high-capacity CNNs to bottom-up region proposals: localize and segment objects
2. when labeled training data is scarce, supervised pre-training for an auxiliary task(**image classification**) + domain-specific fine-tuning(**detection**), yields a significant performance boost
#### combing
* computer vision: classification tools
* deep learning: bottom-up region proposals and CNNs

## Introduction
* Last decade: SIFT and HOG: blockwise orientation histograms ~ cells in V1.  -> More stages are needed according to visual system!  
* an early attempt: neocognitron(lacking supervised learning alg)  
* 1990s: heavy use in CNNs 
* later: SVMs more popular
* 2012: CNN reborn, **To what extent do the CNN classification results on ImageNet generalize to object detection results on the PASCAL VOC Challenge??**  
**R-CNN is the first to show CNN is better for object detection!**  

### First Challenge in Detection: Localization
#### localization -> regression?
not good in practice.  
#### build a sliding-window detector?
CNN need to be small to maintain high spatial resolution, bad.  
#### recognition using regions
1. generates ~2000 region proposals for input image.  
2. transform proposed regions to fixed-size by affine image warping.  
3. input each region into CNN to extract its feature.  
4. classify each region with category-specific linear SVMs.  

### Second Challenge in Detection: labeled data is scarce
#### unsupervised pre-training + supervised fine-tuning?  
conventional solution.
#### supervised pre-training on large dataset + domain-specific fine-tuning on small dataset
effective paradigm for learning high-capacity CNNs when data is scarce.  
* people have shown that CNN can be used as a blackbox feature extractor, working on several recognition tasks!  

### Efficiency
* all CNN parameters are shared across all categories
* feature vector computed has relatively low dimension(4096)
* **As many classes as you want!** the only class-specific computations are dot products between features and SVM weights and non-maximum suppression.   

### Failure modes of R-CNN
under construction
  
### R-CNN could work beyond object detection
Because it operates on regions, R-CNN has extended to semantic segmentation task.  

## Object detection with R-CNN
### Module Design
#### Region Proposals
##### region proposal methods:
* objectness
* selective search
* category-independent object proposals
* constrained parametric min-cuts(CPMC)
* multi-scale combinatorial grouping
* ...
##### R-CNN choose:
selective search, only for comparison with prior work!

#### Feature Extraction 
CNN: region proposal -> 4096-dimensional feature vector
##### region warping before CNN
dilate the tight bounding box -> warp to required size -> CNN

### Test-time detection
#### greedy non-maximum suppression(for each class independently)
rejects a region if it has an intersection-over-union(IoU) overlap with a higher scoring selected region larger than a learned threshold.  

### Training
#### Domain-specific fine-tuning
Aside from replacing the CNNâ€™s ImageNetspecific 1000-way classification layer with a randomly initialized (N + 1)-way classification layer (where N is the number of object classes, plus 1 for background), the CNN architecture is unchanged.






